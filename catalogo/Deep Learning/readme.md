## Deep Learning



### CATEGORICAL REPARAMETERIZATION WITH GUMBEL-SOFTMAX

**2017-04-24**

https://arxiv.org/pdf/1611.01144

This paper introduces the Gumbel-Softmax distribution, a continuous approximation of categorical samples that allows for efficient gradient estimation in stochastic neural networks. The authors demonstrate that this method enables backpropagation through categorical variables, overcoming the challenges posed by non-differentiable sampling. The Gumbel-Softmax estimator outperforms existing gradient estimators in structured output prediction and unsupervised generative modeling tasks, and significantly accelerates training in semi-supervised classification scenarios. Key contributions include the formulation of the Gumbel-Softmax distribution, experimental validation of its effectiveness, and its application in semi-supervised learning without costly marginalization.

---

### 2024 Kolmogorovâ€“Arnold Networks

**2024-02-05**

https://arxiv.org/pdf/2404.19756

---