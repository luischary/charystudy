## Multimodal


### improved_llava
- **https://arxiv.org/pdf/2204.14198**
### 2023 LLAVA
- **2023-04-17**
- https://arxiv.org/pdf/2304.08485
### 2023 A Survey on Multimodal Large Language Models
- **2023-06-23**
- https://arxiv.org/pdf/2306.13549
### 2023 NExT-GPT_ Any-to-Any Multimodal LLM
- **2023-09-13**
- https://arxiv.org/pdf/2309.05519
### 2023 Cheap and Quick Efficient Vision-Language_Instruction Tuning for Large Language Models
- **2023-10-24**
- https://arxiv.org/pdf/2305.15023
### 2023 How to Bridge the Gap between Modalities_ A_Comprehensive Survey on Multi-modal Large_Language Model
- **2023-12-19**
- https://arxiv.org/pdf/2311.07594
### 2023 Versatile Vision Encoders for Multimodal Large Language Models
- **2023-12-21**
- https://arxiv.org/pdf/2312.14233
### 2024 Recent Advances in MultiModal Large Language Models
- **2024-01-24**
- https://arxiv.org/pdf/2401.13601
### 2024 Byte Models are Digital World Simulators
- **2024-02-29**
- https://arxiv.org/pdf/2402.19155
### 2024 An Automated Pipeline for Generating Synthetic_Multi-modal Datasets
- **2024-05-03**
- https://arxiv.org/pdf/2403.03194
### 20240518 Uni-MoE
- **2024-05-18**
- https://arxiv.org/pdf/2405.11273
### 202408 LAW OF VISION REPRESENTATION IN MLLMS
- **2024-08-29**
- https://arxiv.org/pdf/2408.16357