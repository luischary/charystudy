## Video -> Consistency



### FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention

**2024-07-29**

https://arxiv.org/pdf/2407.19918v1

This paper presents FreeLong, a training-free method for generating long videos by adapting existing short video diffusion models. The authors identify that directly extending short video models leads to significant quality degradation, primarily due to high-frequency component distortion. To address this, they introduce SpectralBlend Temporal Attention (SpectralBlend-TA), which blends low-frequency global features with high-frequency local features during the denoising process. This approach enhances both temporal consistency and video fidelity. The experimental results demonstrate that FreeLong outperforms existing methods in generating coherent long videos and supports multi-prompt generation, making it a practical solution for high-quality video creation without extensive retraining.

---