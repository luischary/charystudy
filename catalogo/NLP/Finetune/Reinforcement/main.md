## NLP -> Finetune -> Reinforcement


### Deep Reinforcement Learning_from Human Preferences
- **2017-07-13**
- https://arxiv.org/pdf/1706.03741
### Training language models to follow instructions with human feedback
- **2022-04-03**
- https://arxiv.org/pdf/2203.02155
### 2023 RLAIF_ Scaling Reinforcement Learning from Human Feedback with AI_Feedback
- **2023-01-09**
- https://arxiv.org/pdf/2309.00267
### 2023 Reinforced Self-Training (ReST) for Language_Modeling
- **2023-08-21**
- https://arxiv.org/pdf/2308.08998
### 20240612 REINFORCE Style_Optimization
- **2024-02-26**
- https://arxiv.org/pdf/2402.1474
### 2024 Teaching Large Language Models to Reason_with Reinforcement Learning
- **2024-07-03**
- https://arxiv.org/pdf/2403.04642
### 202407 The Importance of Online Data
- **2024-07-16**
- https://arxiv.org/pdf/2406.01462
### 20240723 J-BOND
- **2024-07-19**
- https://arxiv.org/pdf/2407.14622
### 202407 A General_Framework for Steerable Multi-Objective_Finetuning
- **2024-07-22**
- https://arxiv.org/pdf/2407.15762